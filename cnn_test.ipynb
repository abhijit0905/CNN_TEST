{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d57cfd99-0dd8-42b1-9923-23184af67dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after convolution:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "import numpy as np\n",
    "\n",
    "# Define a 5x5 image matrix\n",
    "image = np.array([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [6, 7, 8, 9, 10],\n",
    "    [11, 12, 13, 14, 15],\n",
    "    [16, 17, 18, 19, 20],\n",
    "    [21, 22, 23, 24, 25]\n",
    "])\n",
    "\n",
    "# Define a 3x3 filter (kernel)\n",
    "filter_kernel = np.array([\n",
    "    [0, 1, 0],\n",
    "    [1, -4, 1],\n",
    "    [0, 1, 0]\n",
    "])\n",
    "\n",
    "# Get the dimensions of the image and the filter\n",
    "image_height, image_width = image.shape\n",
    "filter_height, filter_width = filter_kernel.shape\n",
    "\n",
    "# The output matrix dimensions (after convolution)\n",
    "output_height = image_height - filter_height + 1\n",
    "output_width = image_width - filter_width + 1\n",
    "output = np.zeros((output_height, output_width))\n",
    "\n",
    "# Perform convolution\n",
    "for i in range(output_height):\n",
    "    for j in range(output_width):\n",
    "        # Extract the region of interest from the image (submatrix)\n",
    "        region = image[i:i+filter_height, j:j+filter_width]\n",
    "        \n",
    "        # Perform element-wise multiplication and sum the result\n",
    "        output[i, j] = np.sum(region * filter_kernel)\n",
    "\n",
    "# Display the output of the convolution\n",
    "print(\"Output after convolution:\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aec3ec5-0d12-4b7a-8d05-16b81639bd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after max pooling:\n",
      "[[ 6.  8.]\n",
      " [14. 16.]]\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "import numpy as np\n",
    "\n",
    "# Define a 4x4 feature map\n",
    "feature_map = np.array([\n",
    "    [1, 3, 2, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12],\n",
    "    [13, 14, 15, 16]\n",
    "])\n",
    "\n",
    "# Define the pool size (2x2)\n",
    "pool_size = 2\n",
    "\n",
    "# Calculate the dimensions of the output feature map\n",
    "output_height = feature_map.shape[0] // pool_size\n",
    "output_width = feature_map.shape[1] // pool_size\n",
    "output = np.zeros((output_height, output_width))\n",
    "\n",
    "# Perform max pooling\n",
    "for i in range(output_height):\n",
    "    for j in range(output_width):\n",
    "        # Extract the region (2x2 window)\n",
    "        region = feature_map[i*pool_size:(i+1)*pool_size, j*pool_size:(j+1)*pool_size]\n",
    "        \n",
    "        # Take the maximum value in the region\n",
    "        output[i, j] = np.max(region)\n",
    "\n",
    "# Display the output of max pooling\n",
    "print(\"Output after max pooling:\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2978484f-c70f-46a7-ad1e-c33f96c6ca43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after ReLU activation:\n",
      "[[ 1  0  3  0]\n",
      " [ 0  6  0  8]\n",
      " [ 9  0 11  0]\n",
      " [ 0 14  0 16]]\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "import numpy as np\n",
    "\n",
    "# Define a sample feature map (can be output from a convolutional layer)\n",
    "feature_map = np.array([\n",
    "    [1, -2, 3, -4],\n",
    "    [-5, 6, -7, 8],\n",
    "    [9, -10, 11, -12],\n",
    "    [-13, 14, -15, 16]\n",
    "])\n",
    "\n",
    "# Apply the ReLU activation function\n",
    "relu_output = np.maximum(0, feature_map)\n",
    "\n",
    "# Display the output after ReLU\n",
    "print(\"Output after ReLU activation:\")\n",
    "print(relu_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "399c4f66-ad6b-4e31-b953-1c141a7e9dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2000 - loss: 2.2539\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6000 - loss: 1.5978\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.9000 - loss: 1.1779\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.8167\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 0.5297\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21632</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">216,330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21632\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │       \u001b[38;5;34m216,330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">649,952</span> (2.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m649,952\u001b[0m (2.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">216,650</span> (846.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m216,650\u001b[0m (846.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">433,302</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m433,302\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Define random input data (e.g., 10 samples of 28x28 images with 1 channel)\n",
    "# This could represent grayscale images of size 28x28.\n",
    "input_data = np.random.random((10, 28, 28, 1))  # Shape: (batch_size, height, width, channels)\n",
    "\n",
    "# Step 2: Define the CNN model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add a Convolutional Layer with 32 filters, a 3x3 kernel, and ReLU activation\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "# Add a Flatten layer to reshape the output of the convolutional layer to a 1D vector\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Add a Fully Connected (Dense) Layer with 10 units (assuming 10 classes for classification)\n",
    "model.add(layers.Dense(10, activation='softmax'))  # softmax for multi-class classification\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Define random target labels for training (10 samples, 10 classes)\n",
    "# For the sake of demonstration, we create random labels (one-hot encoded)\n",
    "target_labels = np.random.randint(0, 10, size=(10,))\n",
    "target_labels = tf.keras.utils.to_categorical(target_labels, num_classes=10)\n",
    "\n",
    "# Step 5: Train the model on the random data\n",
    "model.fit(input_data, target_labels, epochs=5)\n",
    "\n",
    "# Print the model summary to see the architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee6446-f7ee-435a-b149-9d346c146240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.0903 - loss: 2.4878\n",
      "Epoch 2/5\n"
     ]
    }
   ],
   "source": [
    "#5import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Generate Synthetic Data (Random Noise as Images)\n",
    "num_samples = 1000  # Number of images in the dataset\n",
    "image_size = 28  # Each image is 28x28 pixels\n",
    "num_classes = 10  # Number of classes for classification\n",
    "\n",
    "# Generate random images (e.g., 28x28 grayscale images)\n",
    "X_train = np.random.random((num_samples, image_size, image_size, 1))\n",
    "\n",
    "# Generate random labels (one-hot encoded)\n",
    "y_train = np.random.randint(0, num_classes, num_samples)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "# Step 2: Define a Simple CNN Model\n",
    "model = tf.keras.Sequential([\n",
    "    # Convolutional Layer with 32 filters and a 3x3 kernel\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size, image_size, 1)),\n",
    "    \n",
    "    # Flatten the output of the convolutional layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # Fully Connected Layer (Dense) with 10 units (for 10 classes)\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the Model on the Synthetic Data\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "# Step 5: Display the Model Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b088c7ec-62f2-49eb-9888-dc2251dbc6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a00fcfe-c937-414b-9c6c-fd6e7b074c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Generate Synthetic Data (Random Noise as Images)\n",
    "num_samples = 1000  # Number of images in the dataset\n",
    "image_size = 28  # Each image is 28x28 pixels\n",
    "num_classes = 10  # Number of classes for classification\n",
    "\n",
    "# Generate random images (e.g., 28x28 grayscale images)\n",
    "X_train = np.random.random((num_samples, image_size, image_size, 1))  # Shape: (num_samples, 28, 28, 1)\n",
    "\n",
    "# Generate random labels (one-hot encoded)\n",
    "y_train = np.random.randint(0, num_classes, num_samples)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "# Step 2: Define the CNN Model\n",
    "model = tf.keras.Sequential([\n",
    "    # Convolutional Layer with 32 filters, a 3x3 kernel, and ReLU activation\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size, image_size, 1)),\n",
    "    \n",
    "    # Max-Pooling Layer with a 2x2 window\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Flatten the output of the convolutional layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # Fully Connected (Dense) Layer with 10 units (for 10 classes)\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the Model on the Synthetic Data\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "# Step 5: Display the Model Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66b0d64-05cd-47c1-86b1-42b2f7a1fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Generate Synthetic Data (Random Noise as Images)\n",
    "num_samples = 1000  # Number of images in the dataset\n",
    "image_size = 28  # Each image is 28x28 pixels\n",
    "num_classes = 10  # Number of classes for classification\n",
    "\n",
    "# Generate random images (e.g., 28x28 grayscale images)\n",
    "X_train = np.random.random((num_samples, image_size, image_size, 1))  # Shape: (num_samples, 28, 28, 1)\n",
    "\n",
    "# Generate random labels (one-hot encoded)\n",
    "y_train = np.random.randint(0, num_classes, num_samples)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "# Step 2: Define the CNN Model\n",
    "model = tf.keras.Sequential([\n",
    "    # Convolutional Layer with 32 filters, a 3x3 kernel, and ReLU activation\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size, image_size, 1)),\n",
    "    \n",
    "    # Max-Pooling Layer with a 2x2 window\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Flatten the output of the convolutional layer (2D to 1D)\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # Fully Connected Layer (Dense) with 128 units and ReLU activation\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    \n",
    "    # Output Layer with 10 units (for 10 classes) and Softmax activation\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the Model on the Synthetic Data\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "# Step 5: Display the Model Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35fad62-88f6-4375-a312-5a0d1ba61b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Generate Synthetic Data (Random Noise as Images)\n",
    "num_samples = 1000  # Number of images in the dataset\n",
    "image_size = 28  # Each image is 28x28 pixels\n",
    "num_classes = 10  # Number of classes for classification\n",
    "\n",
    "# Generate random images (e.g., 28x28 grayscale images)\n",
    "X_train = np.random.random((num_samples, image_size, image_size, 1))  # Shape: (num_samples, 28, 28, 1)\n",
    "\n",
    "# Generate random labels (one-hot encoded)\n",
    "y_train = np.random.randint(0, num_classes, num_samples)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "# Step 2: Define the CNN Model with Batch Normalization\n",
    "model = tf.keras.Sequential([\n",
    "    # Convolutional Layer with 32 filters, a 3x3 kernel, and ReLU activation\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), input_shape=(image_size, image_size, 1)),\n",
    "    \n",
    "    # Batch Normalization Layer\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # ReLU Activation Function\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # Max-Pooling Layer with a 2x2 window\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Flatten the output of the convolutional layer (2D to 1D)\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # Fully Connected Layer (Dense) with 128 units and ReLU activation\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    \n",
    "    # Output Layer with 10 units (for 10 classes) and Softmax activation\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the Model on the Synthetic Data\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "# Step 5: Display the Model Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818de3d7-56c3-4654-98ba-626bda108e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Generate Synthetic Data (Random Noise as Images)\n",
    "num_samples = 1000  # Number of images in the dataset\n",
    "image_size = 28  # Each image is 28x28 pixels\n",
    "num_classes = 10  # Number of classes for classification\n",
    "\n",
    "# Generate random images (e.g., 28x28 grayscale images)\n",
    "X_train = np.random.random((num_samples, image_size, image_size, 1))  # Shape: (num_samples, 28, 28, 1)\n",
    "\n",
    "# Generate random labels (one-hot encoded)\n",
    "y_train = np.random.randint(0, num_classes, num_samples)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "# Step 2: Define the CNN Model with Dropout Regularization\n",
    "model = tf.keras.Sequential([\n",
    "    # Convolutional Layer with 32 filters, a 3x3 kernel, and ReLU activation\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), input_shape=(image_size, image_size, 1)),\n",
    "    \n",
    "    # Dropout Layer with a dropout rate of 0.25\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    # ReLU Activation Function\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # Max-Pooling Layer with a 2x2 window\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Flatten the output of the convolutional layer (2D to 1D)\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # Fully Connected Layer (Dense) with 128 units and ReLU activation\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    \n",
    "    # Dropout Layer with a dropout rate of 0.5 for regularization\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Output Layer with 10 units (for 10 classes) and Softmax activation\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the Model on the Synthetic Data\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "# Step 5: Display the Model Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a122b-8e14-4bb1-9a87-19bd25b2315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the pre-trained VGG16 model without the top (fully connected) layers\n",
    "vgg16_model = tf.keras.applications.VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "# Print the model summary (architecture)\n",
    "vgg16_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693b363-5759-4658-a10c-31b5ed96d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Generate Synthetic Data (Random Noise as Images)\n",
    "num_samples = 1000  # Number of images in the dataset\n",
    "image_size = 28  # Each image is 28x28 pixels\n",
    "num_classes = 10  # Number of classes for classification\n",
    "\n",
    "# Generate random images (e.g., 28x28 grayscale images)\n",
    "X_train = np.random.random((num_samples, image_size, image_size, 1))  # Shape: (num_samples, 28, 28, 1)\n",
    "\n",
    "# Generate random labels (one-hot encoded)\n",
    "y_train = np.random.randint(0, num_classes, num_samples)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "# Step 2: Define the CNN Model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), input_shape=(image_size, image_size, 1)),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # Output layer with 10 classes\n",
    "])\n",
    "\n",
    "# Step 3: Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the Model on the Synthetic Data and capture the history\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "# Step 5: Plot the Accuracy and Loss Graphs\n",
    "# Plotting accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss', color='red')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75eab9b-1c9e-4ee4-afcb-e570ae2ef44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the pre-trained ResNet50 model without the top (fully connected) layers\n",
    "resnet50_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=True)\n",
    "\n",
    "# Print the model summary (architecture)\n",
    "resnet50_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d16d9-2a49-4cec-a63b-598e5cc46c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Generate Synthetic Data (Random Noise as Images)\n",
    "num_samples = 1000  # Number of images in the dataset\n",
    "image_size = 28  # Each image is 28x28 pixels\n",
    "num_classes = 10  # Number of classes for classification\n",
    "\n",
    "# Generate random images (e.g., 28x28 grayscale images)\n",
    "X_train = np.random.random((num_samples, image_size, image_size, 1))  # Shape: (num_samples, 28, 28, 1)\n",
    "\n",
    "# Generate random labels (one-hot encoded)\n",
    "y_train = np.random.randint(0, num_classes, num_samples)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "# Step 2: Define the Basic CNN Model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), input_shape=(image_size, image_size, 1)),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')  # Output layer with 10 classes\n",
    "])\n",
    "\n",
    "# Step 3: Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the Model and Print the Loss and Accuracy After Each Epoch\n",
    "class PrintEpochEnd(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch+1}: Loss = {logs['loss']:.4f}, Accuracy = {logs['accuracy']:.4f}\")\n",
    "\n",
    "# Train the model and pass the custom callback to print loss and accuracy after each epoch\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, callbacks=[PrintEpochEnd()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f2fb97-7791-4f37-bd91-e2aa8a19b86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb0766-9f03-4b02-86bf-4ce333df8caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238a059-29c2-4d44-b3de-bcd2cffd6ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
